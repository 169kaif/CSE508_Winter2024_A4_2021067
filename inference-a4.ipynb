{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":36387,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":30648}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#make imports\n\nimport os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\n\nnltk.download('wordnet')\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n\n#method to preprocess the text\ndef preprocess_text(text):\n\n    #remove the html tags / links\n    text = re.sub(r'<.*?>', '', text)\n\n    #remove special characters\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n\n    #lemmatize the text\n    lemmatizer = WordNetLemmatizer()\n    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n\n    #normalize the text\n    text = text.lower()\n\n    return text\n\n#load the saved model\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\nmodel.load_state_dict(torch.load(\"/kaggle/input/inference_model/pytorch/inference_slug/1/finetuned_final_final.pth\"), strict=False)\n\n#take input from user\ninput_text = input(\"Enter the text: \")\n\n#preprocess the input text\ninput_text = preprocess_text(input_text)\n\n#send model to gpu\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n#generate summary\nmodel.eval()\n\ndef generate_summary(review_text):\n    # tokenize input review\n    inputs = tokenizer.encode(review_text+\" TL;DR \", return_tensors='pt').to(device)\n\n    # generate summary\n    with torch.no_grad():\n        summary_ids = model.generate(inputs, max_length=len(inputs[0])+31, num_beams=4, repetition_penalty=3.0, length_penalty=3.0, early_stopping=False)\n    \n    # decode summary\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary\n\ngen_summary = generate_summary(input_text).split(\"TL;DR\")[-1].strip()\nprint(\"The generated summary is: \", gen_summary)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-22T17:11:17.416556Z","iopub.execute_input":"2024-04-22T17:11:17.417336Z","iopub.status.idle":"2024-04-22T17:12:40.147448Z","shell.execute_reply.started":"2024-04-22T17:11:17.417292Z","shell.execute_reply":"2024-04-22T17:12:40.146163Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd63c1860c5f4a4a82cab5e1f75ff276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9bc6bb86f384b4f82e71cdb4fa0f1d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba9feab540224669ade4970ae957b9fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be67b32318240d98a36186c7da30e9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"641151b6b2f54b708b2874306dcee50c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77eb316d4bb6448c987ba6f216f3f8b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09ef6faf59064c4bbc74b2312081e2b3"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"Enter the text:  \"I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!  We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!  When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!\"\n"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"The generated summary is:  great my dog good treat best i very gluten coffee excellent is tea ydlummyum flavor not likey food productnut snack freeuffsese these delicious\n","output_type":"stream"}]},{"cell_type":"code","source":"#caculate rouge score\n\n!pip install rouge_score\n\nfrom rouge_score import rouge_scorer\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\n#take actual summary from user\ninput_summary = input(\"Enter the actual summary: \")\nprint(input_summary[:200], gen_summary)\nscores = scorer.score(input_summary[:200], gen_summary)\n\nprint(scores)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T17:12:52.554782Z","iopub.execute_input":"2024-04-22T17:12:52.555420Z","iopub.status.idle":"2024-04-22T17:13:14.207373Z","shell.execute_reply.started":"2024-04-22T17:12:52.555384Z","shell.execute_reply":"2024-04-22T17:13:14.205876Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=86abe8fc5d43047ca7fca0260dfcbb23b52c539eb020d65229a12f883eb99b81\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the actual summary:  The Best Hot Sauce in the World\n"},{"name":"stdout","text":"The Best Hot Sauce in the World great my dog good treat best i very gluten coffee excellent is tea ydlummyum flavor not likey food productnut snack freeuffsese these delicious\n{'rouge1': Score(precision=0.043478260869565216, recall=0.14285714285714285, fmeasure=0.06666666666666667), 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0), 'rougeL': Score(precision=0.043478260869565216, recall=0.14285714285714285, fmeasure=0.06666666666666667)}\n","output_type":"stream"}]}]}